{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Comprehend Tutorial\n",
    "\n",
    "This notebook demonstrates AWS Comprehend natural language processing capabilities including:\n",
    "- Language detection (single and multi-language)\n",
    "- Sentiment analysis\n",
    "- Named entity recognition\n",
    "- Key phrase extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "\n",
    "Import required libraries and initialize the AWS Comprehend client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Setting up the environment...\n",
      "âœ… Environment setup complete!\n",
      "ğŸŒ Using AWS region: eu-west-1\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries and set up our environment\n",
    "import pprint\n",
    "\n",
    "import boto3\n",
    "\n",
    "print(\"ğŸ“š Setting up the environment...\")\n",
    "\n",
    "# Initialize pretty printer for better output formatting\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "# Create Comprehend client\n",
    "comprehend = boto3.client(service_name=\"comprehend\", region_name=\"eu-west-1\")\n",
    "\n",
    "print(\"âœ… Environment setup complete!\")\n",
    "print(f\"ğŸŒ Using AWS region: {comprehend.meta.region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Language Detection\n",
    "\n",
    "Detect the dominant language in a simple English sentence and display confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Testing single-language detection...\n",
      "\n",
      "ğŸ“ Input text:\n",
      "\"The quick brown fox jumps over the lazy dog.\"\n",
      "\n",
      "ğŸŒ Detected languages:\n",
      "- en: 99.59% confidence\n",
      "\n",
      "ğŸ“¦ Raw response:\n",
      "{ 'Languages': [{'LanguageCode': 'en', 'Score': 0.9958776235580444}],\n",
      "  'ResponseMetadata': { 'HTTPHeaders': { 'content-length': '64',\n",
      "                                         'content-type': 'application/x-amz-json-1.1',\n",
      "                                         'date': 'Wed, 03 Dec 2025 13:51:57 '\n",
      "                                                 'GMT',\n",
      "                                         'x-amzn-requestid': 'aea35233-d7b9-4204-acb3-dd640cf5af40'},\n",
      "                        'HTTPStatusCode': 200,\n",
      "                        'RequestId': 'aea35233-d7b9-4204-acb3-dd640cf5af40',\n",
      "                        'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate simple language detection\n",
    "print(\"ğŸ” Testing single-language detection...\")\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "try:\n",
    "    response = comprehend.detect_dominant_language(Text=text)\n",
    "\n",
    "    print(\"\\nğŸ“ Input text:\")\n",
    "    print(f'\"{text}\"')\n",
    "\n",
    "    print(\"\\nğŸŒ Detected languages:\")\n",
    "    for language in response[\"Languages\"]:\n",
    "        print(f\"- {language['LanguageCode']}: {language['Score']:.2%} confidence\")\n",
    "\n",
    "    print(\"\\nğŸ“¦ Raw response:\")\n",
    "    pp.pprint(response)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-language Detection\n",
    "\n",
    "Test language detection on text containing multiple languages (German and French)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Testing multi-language detection...\n",
      "\n",
      "ğŸ“ Input text:\n",
      "\"A: Hallo, wie geht es Ihnen?\n",
      "B: Ã‡a va bien. Merci. Et toi?\"\n",
      "\n",
      "ğŸŒ Detected languages:\n",
      "- de: 76.54% confidence\n",
      "- fr: 23.13% confidence\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate multi-language detection\n",
    "print(\"ğŸ” Testing multi-language detection...\")\n",
    "\n",
    "multilingual_text = \"A: Hallo, wie geht es Ihnen?\\nB: Ã‡a va bien. Merci. Et toi?\"\n",
    "try:\n",
    "    response = comprehend.detect_dominant_language(Text=multilingual_text)\n",
    "\n",
    "    print(\"\\nğŸ“ Input text:\")\n",
    "    print(f'\"{multilingual_text}\"')\n",
    "\n",
    "    print(\"\\nğŸŒ Detected languages:\")\n",
    "    for language in response[\"Languages\"]:\n",
    "        print(f\"- {language['LanguageCode']}: {language['Score']:.2%} confidence\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Sentiment Analysis\n",
    "\n",
    "Analyze the sentiment of a short positive text and display sentiment scores for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sentiment analysis with short text...\n",
      "\n",
      "ğŸ“ Input text:\n",
      "\"Hey, I'm feeling great today!\"\n",
      "\n",
      "ğŸ’­ Sentiment analysis:\n",
      "Overall sentiment: POSITIVE\n",
      "\n",
      "Sentiment scores:\n",
      "- Positive: 99.57%\n",
      "- Negative: 0.05%\n",
      "- Neutral: 0.33%\n",
      "- Mixed: 0.06%\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate simple sentiment analysis\n",
    "print(\"Testing sentiment analysis with short text...\")\n",
    "\n",
    "text = \"Hey, I'm feeling great today!\"\n",
    "try:\n",
    "    response = comprehend.detect_sentiment(Text=text, LanguageCode=\"en\")\n",
    "\n",
    "    print(\"\\nğŸ“ Input text:\")\n",
    "    print(f'\"{text}\"')\n",
    "\n",
    "    print(\"\\nğŸ’­ Sentiment analysis:\")\n",
    "    print(f\"Overall sentiment: {response['Sentiment']}\")\n",
    "    print(\"\\nSentiment scores:\")\n",
    "    for sentiment, score in response[\"SentimentScore\"].items():\n",
    "        print(f\"- {sentiment}: {score:.2%}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Longer Text\n",
    "\n",
    "Analyze sentiment of a longer movie description to show how Comprehend handles larger content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜Š Testing sentiment analysis with longer text...\n",
      "\n",
      "ğŸ“ Input text:\n",
      "----------------------------------------\n",
      "Chronicles the experiences of a formerly successful banker as a prisoner in the gloomy jailhouse of Shawshank after being found guilty of a crime he did not commit. The film portrays the man's unique way of dealing with his new, torturous life; along the way he befriends a number of fellow prisoners, most notably a wise long-term inmate named Red.\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’­ Sentiment analysis:\n",
      "Overall sentiment: NEUTRAL\n",
      "\n",
      "Sentiment scores:\n",
      "- Positive: 7.81%\n",
      "- Negative: 0.32%\n",
      "- Neutral: 91.85%\n",
      "- Mixed: 0.02%\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate sentiment analysis with longer text\n",
    "print(\"ğŸ˜Š Testing sentiment analysis with longer text...\")\n",
    "\n",
    "long_text = (\n",
    "    \"Chronicles the experiences of a formerly successful banker as a prisoner in the gloomy jailhouse \"\n",
    "    \"of Shawshank after being found guilty of a crime he did not commit. The film portrays the man's unique way \"\n",
    "    \"of dealing with his new, torturous life; along the way he befriends a number of fellow prisoners, most notably \"\n",
    "    \"a wise long-term inmate named Red.\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = comprehend.detect_sentiment(Text=long_text, LanguageCode=\"en\")\n",
    "\n",
    "    print(\"\\nğŸ“ Input text:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(long_text)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"\\nğŸ’­ Sentiment analysis:\")\n",
    "    print(f\"Overall sentiment: {response['Sentiment']}\")\n",
    "    print(\"\\nSentiment scores:\")\n",
    "    for sentiment, score in response[\"SentimentScore\"].items():\n",
    "        print(f\"- {sentiment}: {score:.2%}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "Extract and identify named entities (people, organizations, locations) from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ·ï¸  Testing named entity recognition...\n",
      "\n",
      "ğŸ” Analyzing entities in texts:\n",
      "\n",
      "ğŸ“ Text 1: \"Welcome to CEU's Data Engineering course run by Zoltan Toth.\"\n",
      "Found entities:\n",
      "- CEU (ORGANIZATION): 98.75% confidence\n",
      "- Zoltan Toth (PERSON): 99.93% confidence\n",
      "\n",
      "ğŸ“ Text 2: \"Here we learn about the internet, AWS and Data Engineering.\"\n",
      "Found entities:\n",
      "- AWS (ORGANIZATION): 58.52% confidence\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate entity recognition\n",
    "print(\"ğŸ·ï¸  Testing named entity recognition...\")\n",
    "\n",
    "texts = [\n",
    "    \"Welcome to CEU's Data Engineering course run by Zoltan Toth.\",\n",
    "    \"Here we learn about the internet, AWS and Data Engineering.\",\n",
    "]\n",
    "\n",
    "try:\n",
    "    print(\"\\nğŸ” Analyzing entities in texts:\")\n",
    "\n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f'\\nğŸ“ Text {i}: \"{text}\"')\n",
    "        response = comprehend.detect_entities(Text=text, LanguageCode=\"en\")\n",
    "\n",
    "        if response[\"Entities\"]:\n",
    "            print(\"Found entities:\")\n",
    "            for entity in response[\"Entities\"]:\n",
    "                print(f\"- {entity['Text']} ({entity['Type']}): {entity['Score']:.2%} confidence\")\n",
    "        else:\n",
    "            print(\"No entities found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Phrase Detection\n",
    "\n",
    "Identify and extract key phrases from text to understand the main topics and important concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ Testing key phrase detection...\n",
      "\n",
      "ğŸ” Analyzing key phrases in texts:\n",
      "\n",
      "ğŸ“ Text 1: \"Welcome to CEU's Data Engineering course run by Zoltan Toth.\"\n",
      "Found key phrases:\n",
      "- CEU: 100.00% confidence\n",
      "- Data Engineering course: 99.94% confidence\n",
      "- Zoltan Toth: 100.00% confidence\n",
      "\n",
      "ğŸ“¦ Raw response:\n",
      "{ 'KeyPhrases': [ { 'BeginOffset': 11,\n",
      "                    'EndOffset': 14,\n",
      "                    'Score': 0.9999834299087524,\n",
      "                    'Text': 'CEU'},\n",
      "                  { 'BeginOffset': 17,\n",
      "                    'EndOffset': 40,\n",
      "                    'Score': 0.9994303584098816,\n",
      "                    'Text': 'Data Engineering course'},\n",
      "                  { 'BeginOffset': 48,\n",
      "                    'EndOffset': 59,\n",
      "                    'Score': 0.9999920725822449,\n",
      "                    'Text': 'Zoltan Toth'}],\n",
      "  'ResponseMetadata': { 'HTTPHeaders': { 'content-length': '266',\n",
      "                                         'content-type': 'application/x-amz-json-1.1',\n",
      "                                         'date': 'Wed, 03 Dec 2025 14:01:39 '\n",
      "                                                 'GMT',\n",
      "                                         'x-amzn-requestid': '2ada7cee-daa8-4d15-8228-bc67edeae7c1'},\n",
      "                        'HTTPStatusCode': 200,\n",
      "                        'RequestId': '2ada7cee-daa8-4d15-8228-bc67edeae7c1',\n",
      "                        'RetryAttempts': 0}}\n",
      "\n",
      "ğŸ“ Text 2: \"Here we learn about the internet, AWS and Data Engineering.\"\n",
      "Found key phrases:\n",
      "- the internet: 99.97% confidence\n",
      "- AWS: 85.41% confidence\n",
      "- Data Engineering: 84.30% confidence\n",
      "\n",
      "ğŸ“¦ Raw response:\n",
      "{ 'KeyPhrases': [ { 'BeginOffset': 20,\n",
      "                    'EndOffset': 32,\n",
      "                    'Score': 0.9997076392173767,\n",
      "                    'Text': 'the internet'},\n",
      "                  { 'BeginOffset': 34,\n",
      "                    'EndOffset': 37,\n",
      "                    'Score': 0.8540872931480408,\n",
      "                    'Text': 'AWS'},\n",
      "                  { 'BeginOffset': 42,\n",
      "                    'EndOffset': 58,\n",
      "                    'Score': 0.8430337309837341,\n",
      "                    'Text': 'Data Engineering'}],\n",
      "  'ResponseMetadata': { 'HTTPHeaders': { 'content-length': '260',\n",
      "                                         'content-type': 'application/x-amz-json-1.1',\n",
      "                                         'date': 'Wed, 03 Dec 2025 14:01:39 '\n",
      "                                                 'GMT',\n",
      "                                         'x-amzn-requestid': 'f53e4176-65ab-49f3-9d4f-9f1f852535a9'},\n",
      "                        'HTTPStatusCode': 200,\n",
      "                        'RequestId': 'f53e4176-65ab-49f3-9d4f-9f1f852535a9',\n",
      "                        'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate key phrase detection\n",
    "print(\"ğŸ”‘ Testing key phrase detection...\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nğŸ” Analyzing key phrases in texts:\")\n",
    "\n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f'\\nğŸ“ Text {i}: \"{text}\"')\n",
    "        response = comprehend.detect_key_phrases(Text=text, LanguageCode=\"en\")\n",
    "\n",
    "        if response[\"KeyPhrases\"]:\n",
    "            print(\"Found key phrases:\")\n",
    "            for phrase in response[\"KeyPhrases\"]:\n",
    "                print(f\"- {phrase['Text']}: {phrase['Score']:.2%} confidence\")\n",
    "        else:\n",
    "            print(\"No key phrases found.\")\n",
    "\n",
    "        print(\"\\nğŸ“¦ Raw response:\")\n",
    "        pp.pprint(response)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceu-cloud-class-eXFNao7V-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
